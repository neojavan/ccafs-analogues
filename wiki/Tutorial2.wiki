-------
= *_ CAUTION: this is work in progress and still contains errors _* =
----------



= Comparing multiple points =
== Requirements ==
  * Understood tutorial 1
  * Some familiarity with R
  * Not affraid of `*`pply

== Preparing Data ==


{{{
library(analogues)
sites <- read.csv("http://ccafs-analogues.googlecode.com/files/crops.csv")

str(sites)
'data.frame':	100 obs. of  3 variables:
 $ Lat  : num  39.7 10.3 -13.1 -25.8 34.7 ...
 $ Long : num  22.6 -84.3 -76.2 -65 32 ...
 $ yield: int  46 163 85 44 69 43 129 141 5 142 ...

head(sites)
        Lat       Long yield
1  39.66667   22.58333    46
2  10.26667  -84.26667   163
3 -13.11667  -76.20000    85
4 -25.80000  -64.96667    44
5  34.71667   32.05000    69
6  20.68333 -103.33333    43
}}}

Make use of the analogues model

{{{
params <- createParameters(x=76.9, y=29.7, to=NA,
   method="ccafs", hal.rad=c(NA, 0.15),
   hal.mad=c(NA,0.3), hal.mrd=c(1, NA), z=2,
   gcms=c("current","a1b_2020_2049_ukmo_hadgem1","a1b_2020_2049_miroc3_2_hires", "a1b_2020_2049_ipsl_cm4"),
   vars=c("tmean", "prec"), weights=c("dtr",1), ndivisions=12,
   climate.data="../analogues_data/current_a1b_2030", ext=".asc", direction="backwd",
   growing.season=1:12, across.year=T, keep.lag=F, normalise=F)
}}}

== Load climate data ==
Since have already created a _params_ object, we can take advantage of the _loadData()_ function from the analogues package to load all data at once.
{{{
training_data <- loadData(params)
}}}
=== Some data cleaning ===
It is likely that some sites will have coordinates that are not covered with our raster, we want to eliminate those sites
{{{
nrow(sites)
[1] 100
}}}
For each site we check whether or not a value is available for the first grid. If there is a value available for the first gird, all other grids should be fine too, since they all have the same extent.
{{{
sites <- sites[!is.na(extract(training_data[[1]][[1]], as.matrix(sites[, c("Long", "Lat")]))), ]
nrow(sites)
[1] 95
}}}
== Extract training data ==
It is a lot faster we load the climate data only once for every point of interest (poi), at the beginning of the analysis and reuse it again afterwards. 

{{{
poi_training <- lapply(training_data, function(x) extract(x, as.matrix(sites[, c("Long", "Lat")])))
}}}

This returns a list of matrixes. Each matrix has the dimension of number of points `*` 12, the list has length 8, because we have 4 gcms and two variables (2 `*` 8)

== Loading weights ==

{{{
weights_data <- loadWeights(params)
}}}

== Extracting weights ==
Extracting weights is a little bit more difficult. Because grids can be weighted by an other grid or by a constant value.
{{{
poi_weights <- list()

for (i in 1:length(weights_data)) {
  if (is.numeric(weights_data[[i]]) | is.character(weights_data[[i]])) {
    poi_weights[[i]] <- matrix(rep(as.numeric(weights_data[[i]]), (nrow(sites) * nlayers(training_data[[1]]))), ncol=nlayers(training_data[[1]]))
  } else {
    poi_weights[[i]] <- extract(weights_data[[i]],as.matrix(sites[, c("Long", "Lat")]))
  }
}
}}}
== Current disimilarity for one point ==
To calculate current dissimilaritiy, we can make use of the underlying _ccafsMPoints()_ function

E.g. to calculate dissimilarities from the first point to all points
{{{
dis_from_pt_1 <- ccafsMPoints(ref.t=lapply(poi_training[1:2], function(x) x[1,]), 
 poi.t=poi_training[1:2],  
 ref.w=lapply(poi_weights[1:2], function(x) x[1,]),
 poi.w=poi_training[1:2],
 z=2)
}}}
== Current dissimilarity for many points ==
we can easily apply this function to all points 

{{{
dis_current <- lapply(1:nrow(sites), function(pt) ccafsMPoints(ref.t=lapply(poi_training[1:2], function(x) x[pt,]), 
 poi.t=poi_training[1:2],  
 ref.w=lapply(poi_weights[1:2], function(x) x[pt,]),
 poi.w=poi_training[1:2],
 z=2))
}}}
 
we can obtain the dissimilarities from point n to all other points by:
{{{
dis_current[[n]]
}}}
e.g.
{{{
dis_current[[23]]
 [1]  3395.1337 10280.4005   675.1275  3116.8990  3259.5874  4423.6284
 [7]  3116.8990  3859.2165  3277.7336  5103.3787  3858.8737  6151.5272
[13]  3222.2635  3470.0988  2246.4836  3979.5468  3589.7453  6388.2515
[19]  3236.8243  3038.3087  4445.3497  3192.5736     0.0000  3787.5123
[25]  3470.0988  3282.7151  2032.7642  3410.1311  4293.4085  4363.6686
[31]  3226.4886  3807.9293  4019.8943  3282.7151  5441.3842 21767.4184
[37]  3731.5949  5933.4108  2738.5438  3395.1337  5658.0872  7333.4043
[43]  3981.5042  5154.4351  8418.1029  3832.0010  2670.9966  8361.4731
[49]  3695.8744  3541.8455  3050.4915  4202.3001  3326.6342  4152.3145
[55] 10280.4005  3979.5468  2848.3014  3588.1453  3307.3742  3776.8307
[61]  4415.0584  3561.4933  2268.6822  6138.4543  3251.0059  3076.2044
[67]  4097.7051  4857.5163  3480.4072  3407.6777  7848.1491  4480.0725
[73]  5582.2977  5704.9711  3267.9974  3717.9343  3845.2540  3106.8596
[79]  4219.0669  3329.9383  4601.8583  4415.0584 12122.1920  4299.7627
[85]  3188.7487  1688.5925 15501.6915  2467.3005  3614.0378  5132.5505
[91]  5023.3430  3276.2368  3116.8990   640.2563  2962.3671

}}}
and it should have a dissimilarity of 0 to with itself
{{{
dis_current[[23]][23] == 0
[1] TRUE
}}}
we can quickly check that this applies for all points
{{{
all(sapply(1:nrow(sites), function(x) dis_current[[x]][x] == 0))
[1] TRUE
}}}

We might be interested in points that a very similar to point 33.
{{{
from_33 <- cbind(sites, dis_current[[33]])
}}}
We can get the 10 closest points by: (n.b. we use [2:11,] to omit the first point, which is point 44)
{{{
from_33[order(from_33[,4]),][2:11,]
}}}
We can also plot point dissimilarity versus yield in order to find a point with high yield and low dissimilarity.
{{{
plot(from_33[,4], from_33[,3], ylab="Yield", xlab="Dissimilarity", las=T, main="Dissimilarities from point 33")
grid()
}}}

http://ccafs-analogues.googlecode.com/files/from33.png

Points in the upper left corner will be of greatest interest to us. 

== Current dissimilarities for many points with a lag ==

We can extent out analysis by comparing not only months as they are, varying the starting point during the years. In order to achieve that we will roll over reference points, i.e. start with the first devision, second division until the last division.

=== roll ===
First we create a 'roll', which we will use as a template.
{{{
roll.v <- c()
months <- 1:params$ndivisions
for (i in 1:length(months)) {
   roll.v <- c(roll.v,(months[c(i:length(months),0:(i-1))]))  
}
roll <- matrix(data=roll.v, ncol=length(months), byrow=TRUE)
  
# cut roll to the actual growin period
roll <- roll[ , params$growing.season]
}}}

=== Function for dissimilarities ===

We will write a simple function to run ccafsMPoints for a given point over the roll and summarizes the results by taking the minimum value.

{{{
ccafsMPoints_rolled <- function(pt, poi_training, poi_w, roll) {
  this_res <- matrix(rep(NA, nrow(roll) * nrow(poi_training[[1]])), ncol=nrow(roll))
  for (i in 1:nrow(roll)) {
    this_res[,i] <- ccafsMPoints(ref.t=lapply(poi_training[1:2], function(x) x[pt,roll[i,]]), 
    poi.t=poi_training[1:2],  
    ref.w=lapply(poi_weights[1:2], function(x) x[pt,roll[i,]]),
    poi.w=poi_training[1:2],
    z=2)
  }
  return(apply(this_res, 1, min))
}
}}}

now we just apply this function to each site.
{{{
dis_current_rolled <- lapply(1:nrow(sites), function(pt) ccafsMPoints_rolled(pt, poi_training, poi_w, roll))
}}}

we can test again the results for consitency
all(sapply(1:nrow(sites), function(x) dis_current_rolled[[x]][x] == 0))

we can plot the rolled vs not rolled

{{{
plot(dis_current[[1]], dis_current_rolled[[1]], xlab="Dissimilarities without lag", ylab="Dissimilarities with lag", main="Effect of Lag")
}}}

and see that there are some differences

Finally we want to apply, everything to different futur scenarios to do so we modify our function